[{"path":"http://marcelortiz.com/triplediff/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Marcelo Ortiz-Villavicencio Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"http://marcelortiz.com/triplediff/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Marcelo Ortiz-Villavicencio. Author, maintainer. Pedro H. C. Sant'Anna. Author.","code":""},{"path":"http://marcelortiz.com/triplediff/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ortiz-Villavicencio M, Sant'Anna P (2025). “Better Understanding Triple Differences Estimators.” ArXiv. https://arxiv.org/abs/2505.09942. Ortiz-Villavicencio M, Sant'Anna P (2025). “triplediff: Triple Differences Estimators.” R package version 0.1.0, http://marcelortiz.com/triplediff/.","code":"@Article{,   title = {Better Understanding Triple Differences Estimators},   author = {Marcelo Ortiz-Villavicencio and Pedro H.C. Sant'Anna},   year = {2025},   journal = {ArXiv},   url = {https://arxiv.org/abs/2505.09942}, } @Misc{,   title = {triplediff: Triple Differences Estimators},   author = {Marcelo Ortiz-Villavicencio and Pedro H.C. Sant'Anna},   year = {2025},   note = {R package version 0.1.0},   url = {http://marcelortiz.com/triplediff/}, }"},{"path":"http://marcelortiz.com/triplediff/index.html","id":"triple-differences-estimators-","dir":"","previous_headings":"","what":"Triple Differences Estimators","title":"Triple Differences Estimators","text":"triplediff R package computing average treatment effects Triple Differences Designs (also known Difference--Differences--Differences DDD). DDD designs widely used empirical work relax parallel trends assumptions Difference--Differences settings. package provides functions estimate group-time average treatment effect event-study type estimands associated DDD designs. setups allowed : Two-periods Multiple Periods DDD. Single Treatment Date Variation Treatment Timing (.e., staggered adoption). Conditional Unconditional DDD parallel trends assumptions. triplediff package implements framework proposed : Ortiz-Villavicencio, Marcelo Pedro H.C. Sant’Anna. “Better Understanding Triple Differences Estimators”, 2025.","code":""},{"path":"http://marcelortiz.com/triplediff/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Triple Differences Estimators","text":"can install latest development version triplediff Github :","code":"# install.packages(\"devtools\") devtools::install_github(\"marcelortizv/triplediff\")  library(triplediff)"},{"path":"http://marcelortiz.com/triplediff/index.html","id":"quick-start-how-to-use-triplediff","dir":"","previous_headings":"","what":"Quick Start: How to use triplediff","title":"Triple Differences Estimators","text":"provide quick start example illustrate main features package. UX designed similar package, users familiar feel comfortable using triplediff. ddd main function computing DDD estimators proposed Ortiz-Villavicencio Sant’Anna (2025). core, ddd employs regression adjustment, inverse probability weighing, doubly robust estimators valid conditional DDD parallel trends. use ddd, minimal data requirements include: id: Unit unique identifier (e.g., firm, individual, etc.). column name associated parameter idname. period: Time identifier (e.g., year, month, etc.). column name associated parameter tname. outcome: Outcome variable interest. column name associated parameter yname. state: First period treatment enabled particular unit. positive number treated units defines group unit belongs . takes value 0 Inf never-enabling units. column name associated parameter gname. partition: indicator variable 1 units eligible treatment 0 otherwise. column name associated parameter pname. following two simplified examples use ddd function. first one two-period DDD setup, second one multiple-period DDD setup staggered treatment adoption.","code":""},{"path":"http://marcelortiz.com/triplediff/index.html","id":"case-two-periods-ddd-with-covariates","dir":"","previous_headings":"Quick Start: How to use triplediff","what":"Case: Two-Periods DDD with covariates","title":"Triple Differences Estimators","text":"First, simulate data built-function gen_dgp_2periods generates two-period DDD setup single treatment date. function receives number units type DGP design generate. gen_dgp_2periods function returns data frame required columns ddd function 4 covariates. Now can estimate average treatment effect treated (ATT) using ddd function. can also leverage fact estimators doubly robust rely data-driven models estimating nuisance parameters. example, can use flexible machine learning like xgboost estimate outcome models ranger (Random Forest) estimate propensity scores. engine behind implementation mlr3 package, provides unified interface --shelf ML algorithms R, DoubleML package, implements double machine learning framework. Since DGP linear, can use regr.lm classif.log_reg learners mlr3learners estimate outcome propensity score models, respectively, compare previous results. results suggest close agreement doubly robust estimator double machine learning estimator, expected since DGP linear. difference estimates due randomness cross-fitting procedure used double machine learning.","code":"set.seed(1234) # Set seed for reproducibility # Simulate data for a two-periods DDD setup df <- gen_dgp_2periods(   size = 5000, # Number of units   dgp_type = 1 # Type of DGP design )$data  head(df) #> Key: <id> #>       id state partition  time        y        cov1       cov2      cov3 #>    <int> <num>     <num> <int>    <num>       <num>      <num>     <num> #> 1:     1     0         0     1 209.9152 -0.97080934 -1.1726958 2.3893945 #> 2:     1     0         0     2 417.5260 -0.97080934 -1.1726958 2.3893945 #> 3:     2     0         0     1 211.4919  0.02591115  0.2763066 0.1063123 #> 4:     2     0         0     2 420.3656  0.02591115  0.2763066 0.1063123 #> 5:     3     0         0     1 221.9431  0.97147321 -0.4292088 0.5012794 #> 6:     3     0         0     2 440.9623  0.97147321 -0.4292088 0.5012794 #>          cov4 cluster #>         <num>   <int> #> 1:  0.2174955      39 #> 2:  0.2174955      39 #> 3: -0.1922253      29 #> 4: -0.1922253      29 #> 5:  1.1027248      44 #> 6:  1.1027248      44 # Estimate the average treatment effect on the treated, ATT(2,2)  att_22 <- ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",              pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,              data = df, control_group = \"nevertreated\", est_method = \"dr\")  summary(att_22) #>  Call: #> ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",  #>     pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,  #>     data = df, control_group = \"nevertreated\", est_method = \"dr\") #> =========================== DDD Summary ============================== #>  DR-DDD estimation for the ATT:  #>      ATT       Std. Error    Pr(>|t|)  [95% Ptwise. Conf. Band]               #>     -0.0780       0.0828       0.3463      -0.2404       0.0843               #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Panel data #>  Outcome variable: y #>  Qualification variable: partition #>  No. of units at each subgroup: #>    treated-and-eligible: 1232 #>    treated-but-ineligible: 1285 #>    eligible-but-untreated: 1256 #>    untreated-and-ineligible: 1227 #>  --------------------------- Algorithms ------------------------------ #>  Outcome Regression estimated using: OLS #>  Propensity score estimated using: Maximum Likelihood #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.05 #>  Analytical standard errors. #>  Type of confidence band:  Pointwise Confidence Interval #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details. library(mlr3) library(mlr3learners)  # suppress messages during fitting lgr::get_logger(\"mlr3\")$set_threshold(\"warn\") # set learners for nuisance functions learner_lm <- lrn(\"regr.lm\") learner_logit <- lrn(\"classif.log_reg\", predict_type = \"prob\") learners <- list(ml_pa = learner_logit, ml_md = learner_lm)  # estimation att_22_dml <- ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",                   pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,                   data = df, control_group = \"nevertreated\",                   est_method = \"dml\", learners = learners, n_folds = 10)  summary(att_22_dml) #>  Call: #> ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",  #>     pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,  #>     data = df, control_group = \"nevertreated\", est_method = \"dml\",  #>     learners = learners, n_folds = 10) #> =========================== DDD Summary ============================== #>  DML-DDD estimation for the ATT:  #>      ATT       Std. Error    Pr(>|t|)  [95% Ptwise. Conf. Band]               #>     -0.0884       0.0461       0.0554      -0.1788       0.0021               #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Panel data #>  Outcome variable: y #>  Qualification variable: partition #>  No. of units at each subgroup: #>    treated-and-eligible: 1232 #>    treated-but-ineligible: 1285 #>    eligible-but-untreated: 1256 #>    untreated-and-ineligible: 1227 #>  --------------------------- Algorithms ------------------------------ #>  Outcome Regression estimated using: Linear Model #>  Propensity score estimated using: Logistic Regression #>  -------------------------- Cross-fitting  --------------------------- #>  No. of folds:  10 #>  Apply cross-fitting: TRUE #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.05 #>  Analytical standard errors. #>  Type of confidence band:  Pointwise Confidence Interval #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details."},{"path":"http://marcelortiz.com/triplediff/index.html","id":"case-multiple-periods-ddd-with-staggered-treatment-adoption","dir":"","previous_headings":"Quick Start: How to use triplediff","what":"Case: Multiple Periods DDD with staggered treatment adoption","title":"Triple Differences Estimators","text":"case, simulate data built-function gen_dgp_staggered generates multiple-period DDD setup staggered treatment adoption. function receives number units type DGP design generate. gen_dgp_staggered function returns data frame required columns ddd function 4 covariates. Now can estimate group-time average treatment effect treated using ddd function. Next, can aggregate group-time average treatment effect treated obtain event-study type estimates. agg_ddd function allows us aggregate results ddd function. event-study type estimates, can plot results using ggplot library create crisp visualizations.  Finally, can also estimate group-time average treatment effect using GMM-based estimator -yet-treated units comparison group. done setting control_group parameter \"notyettreated\" ddd function. result, can observe standard errors ATT(2,2)ATT(2,2) lower ones obtained control_group = \"nevertreated\" option since leverage additional information -yet-treated units estimation. ⚠️ recommend users read paper details GMM-based procedure difference estimators relying -yet-treated units comparison group.","code":"set.seed(1234) # Set seed for reproducibility # Simulate data for a multiple-period DDD setup with staggered treatment adoption data <- gen_dgp_mult_periods(size = 500, dgp_type = 1)$data  head(data) #> Key: <id> #>       id state partition  time         y        cov1       cov2       cov3 #>    <int> <num>     <num> <int>     <num>       <num>      <num>      <num> #> 1:     1     3         1     1 1371.1923 -0.97080934  1.3995704 1.48834130 #> 2:     1     3         1     2 1690.9157 -0.97080934  1.3995704 1.48834130 #> 3:     1     3         1     3 2034.5661 -0.97080934  1.3995704 1.48834130 #> 4:     2     2         1     1  934.0812  0.02591115 -0.9747527 0.01714001 #> 5:     2     2         1     2 1189.5495  0.02591115 -0.9747527 0.01714001 #> 6:     2     2         1     3 1444.1072  0.02591115 -0.9747527 0.01714001 #>          cov4 cluster #>         <num>   <int> #> 1:  0.3853346      27 #> 2:  0.3853346      27 #> 3:  0.3853346      27 #> 4: -0.7822000      45 #> 5: -0.7822000      45 #> 6: -0.7822000      45 # Estimate the group-time average treatment effect in DDD  att_gt <- ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",                pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,               data = data, control_group = \"nevertreated\",                base_period = \"universal\", est_method = \"dr\")  summary(att_gt) #>  Call: #> ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",  #>     pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,  #>     data = data, control_group = \"nevertreated\", base_period = \"universal\",  #>     est_method = \"dr\") #> =========================== DDD Summary ============================== #>  DR-DDD estimation for the ATT(g,t):  #> Group Time  ATT(g,t)  Std. Error [95% Pointwise  Conf. Band]   #>   2    1       0.0000         NA           NA            NA    #>   2    2      10.4901     0.3613       9.7819       11.1983  * #>   2    3      20.5986     0.3868      19.8405       21.3568  * #>   3    1      -0.4593     0.3660      -1.1767        0.2580    #>   3    2       0.0000         NA           NA            NA    #>   3    3      24.5983     0.3333      23.9450       25.2515  * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Panel data #>  Outcome variable: y #>  Qualification variable: partition #>  Control group: Never Treated #>  No. of units per treatment group: #>   Units enabling treatment at period 3: 198 #>   Units enabling treatment at period 2: 195 #>   Units never enabling treatment: 107 #>  --------------------------- Algorithms ------------------------------ #>  Outcome Regression estimated using: OLS #>  Propensity score estimated using: Maximum Likelihood #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.05 #>  Analytical standard errors. #>  Type of confidence band:  Pointwise Confidence Interval #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details. es_e <- agg_ddd(att_gt, type = \"eventstudy\")  summary(es_e) #>  Call: #> agg_ddd(ddd_obj = att_gt, type = \"eventstudy\") #> ========================= DDD Aggregation ============================ #>  Overall summary of ATT's based on event-study/dynamic aggregation:  #>      ATT    Std. Error     [ 95%  Conf. Int.]   #>  19.0983        0.3213    18.4685     19.7281 * #>  #>  Event Study: #>  Event time Estimate Std. Error [95% Ptwise.  Conf. Band]   #>          -2  -0.4593     0.3660       -1.1767      0.2580   #>          -1   0.0000         NA            NA          NA   #>           0  17.5980     0.4095       16.7955     18.4005 * #>           1  20.5986     0.3868       19.8405     21.3568 * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Outcome variable: y #>  Qualification variable: partition #>  Control group:  Never Treated #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.05 #>  Analytical standard errors. #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details. es_df <- with(es_e$aggte_ddd, {     tibble::tibble(period   = egt,                    estimate = att.egt,                    ci_lower = estimate - crit.val.egt * se.egt,                    ci_upper = estimate + crit.val.egt * se.egt)   })   all_per <- sort(unique(es_df$period))  p <- ggplot(es_df, aes(period, estimate)) +     geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper),                   width = .15,                   position = position_dodge(width = .3)) +     geom_point(size = 2.2,                position = position_dodge(width = .3)) +     geom_hline(yintercept = 0, linewidth = .3) +     geom_vline(xintercept = -1, linetype = \"dashed\",                linewidth = .3) +     scale_x_continuous(       breaks = all_per     ) +          labs(title = \"\",          x = \"Event Time\",          y = \"Treatment Effect\") +     theme_bw(base_size = 12) +     theme(plot.title   = element_text(hjust = .25),           legend.position = \"right\")      p # do the same but using GMM-based notyettreated att_gt_nyt <- ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",                pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,               data = data, control_group = \"notyettreated\",                base_period = \"universal\", est_method = \"dr\")  summary(att_gt_nyt) #>  Call: #> ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",  #>     pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,  #>     data = data, control_group = \"notyettreated\", base_period = \"universal\",  #>     est_method = \"dr\") #> =========================== DDD Summary ============================== #>  DR-DDD estimation for the ATT(g,t):  #> Group Time  ATT(g,t)  Std. Error [95% Pointwise  Conf. Band]   #>   2    1       0.0000         NA           NA            NA    #>   2    2      10.1894     0.2759       9.6486       10.7302  * #>   2    3      20.5986     0.3868      19.8405       21.3568  * #>   3    1      -0.4593     0.3660      -1.1767        0.2580    #>   3    2       0.0000         NA           NA            NA    #>   3    3      24.5983     0.3333      23.9450       25.2515  * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Panel data #>  Outcome variable: y #>  Qualification variable: partition #>  Control group: Not yet Treated (GMM-based) #>  No. of units per treatment group: #>   Units enabling treatment at period 3: 198 #>   Units enabling treatment at period 2: 195 #>   Units never enabling treatment: 107 #>  --------------------------- Algorithms ------------------------------ #>  Outcome Regression estimated using: OLS #>  Propensity score estimated using: Maximum Likelihood #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.05 #>  Analytical standard errors. #>  Type of confidence band:  Pointwise Confidence Interval #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details."},{"path":"http://marcelortiz.com/triplediff/index.html","id":"release-note-","dir":"","previous_headings":"","what":"Release Note 📢","title":"Triple Differences Estimators","text":"current version released alpha stage: core features implemented made available users can try provide feedback. Please, aware remains active development, long-term stability guaranteed—APIs may evolve, adding features /breaking changes can occur time, without deprecation cycle. Use GitHub Issues report bugs, request features provide feedback.","code":""},{"path":"http://marcelortiz.com/triplediff/index.html","id":"id_-currently-supported","dir":"","previous_headings":"Release Note 📢","what":"🚀 Currently Supported","title":"Triple Differences Estimators","text":"️✅ Two-period DDD single treatment date. ️✅ Multiple-period DDD single treatment date. ️✅ DDD staggered treatment adoption (.e., two periods variation treatment timing). ️✅ Aggregations procedures (e.g., event-study type estimates). ️✅ GMM-based estimations -yet-treated units comparison group.","code":""},{"path":"http://marcelortiz.com/triplediff/index.html","id":"id_️-not-yet-supported","dir":"","previous_headings":"Release Note 📢","what":"⚠️ Not Yet Supported","title":"Triple Differences Estimators","text":"partially implemented via mlr3 DoubleML --hood. Users can specify models estimating outcome models propensity scores. Currently, two-period DDD single treatment date setting supported. can done easily users. E.g., event-study type estimates can plotted using ggplot2. See quick start example. 🔲 Repeated cross-sectional data. 🔲 Unbalanced panel data.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/agg_ddd.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate Group-Time Average Treatment Effects in Staggered Triple-Differences Designs. — agg_ddd","title":"Aggregate Group-Time Average Treatment Effects in Staggered Triple-Differences Designs. — agg_ddd","text":"agg_ddd function take group-time average treatment effects aggregate smaller number summary parameters staggered triple differences designs. several possible aggregations including \"simple\", \"eventstudy\", \"group\", \"calendar\".  Default \"eventstudy\".","code":""},{"path":"http://marcelortiz.com/triplediff/reference/agg_ddd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate Group-Time Average Treatment Effects in Staggered Triple-Differences Designs. — agg_ddd","text":"","code":"agg_ddd(   ddd_obj,   type = \"eventstudy\",   balance_e = NULL,   min_e = -Inf,   max_e = Inf,   na.rm = FALSE,   boot = NULL,   nboot = NULL,   cband = NULL,   alpha = 0.05 )"},{"path":"http://marcelortiz.com/triplediff/reference/agg_ddd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate Group-Time Average Treatment Effects in Staggered Triple-Differences Designs. — agg_ddd","text":"ddd_obj ddd object (.e., results ddd() function) type type aggregated treatment effect parameter compute. \"simple\" just computes weighted average group-time average treatment effects weights proportional group size. \"eventstudy\" computes average effects across different lengths exposure treatment (event times). overall effect averages effect treatment across positive lengths exposure. default option; \"group\" computes average treatment effects across different groups/cohorts; overall effect averages effect across different groups using group size weights; \"calendar\" computes average treatment effects across different time periods, weights proportional group size; overall effect averages effect across time period. balance_e set (one computes event study), balances sample respect event time.  example, balance_e=2, agg_ddd drop groups exposed treatment least three periods, initial period e=0 well next two periods, e=1 e=2.  ensures composition groups change event time changes. min_e event studies, smallest event time compute dynamic effects .  default, min_e = -Inf effects lengths exposure computed. max_e event studies, largest event time compute dynamic effects .  default, max_e = Inf effects lengths exposure computed. na.rm Logical value remove missing Values analyses. Defaults FALSE. boot Boolean whether compute standard errors using multiplier bootstrap.  standard errors clustered, one must set boot=TRUE. Default value set ddd object.  boot = FALSE, analytical standard errors reported. nboot number bootstrap iterations use.  default value set ddd object, applicable boot=TRUE. cband Boolean whether compute uniform confidence band covers group-time average treatment effects fixed probability 0.95.  order compute uniform confidence bands, boot must also set TRUE.  default value set ddd object alpha level confidence confidence intervals.  default 0.05. Otherwise, use value set ddd object.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/agg_ddd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate Group-Time Average Treatment Effects in Staggered Triple-Differences Designs. — agg_ddd","text":"object (list) class agg_ddd holds results aggregation step.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/agg_ddd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Aggregate Group-Time Average Treatment Effects in Staggered Triple-Differences Designs. — agg_ddd","text":"","code":"#---------------------------------------------------------- # Triple Diff with multiple time periods #----------------------------------------------------------  data <- gen_dgp_mult_periods(size = 500, dgp_type = 1)[[\"data\"]]  out <- ddd(yname = \"y\", tname = \"time\", idname = \"id\",             gname = \"state\", pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,             data = data, control_group = \"nevertreated\", base_period = \"varying\",             est_method = \"dr\") # Simple aggregation agg_ddd(out, type = \"simple\", alpha = 0.10) #>  Call: #> agg_ddd(ddd_obj = out, type = \"simple\", alpha = 0.1) #> ========================= DDD Aggregation ============================ #>  Overall ATT: #>     ATT    Std. Error     [ 90%  Conf. Int.]   #>  19.005        0.3718    18.3935     19.6166 * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Outcome variable: y #>  Qualification variable: partition #>  Control group:  Never Treated #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.1 #>  Analytical standard errors. #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details.  # Event study aggregation agg_ddd(out, type = \"eventstudy\", alpha = 0.10) #>  Call: #> agg_ddd(ddd_obj = out, type = \"eventstudy\", alpha = 0.1) #> ========================= DDD Aggregation ============================ #>  Overall summary of ATT's based on event-study/dynamic aggregation:  #>      ATT    Std. Error     [ 90%  Conf. Int.]   #>  19.2985        0.3653    18.6976     19.8993 * #>  #>  Event Study: #>  Event time Estimate Std. Error [90% Ptwise.  Conf. Band]   #>          -1  -0.2292     0.4289       -0.9346      0.4762   #>           0  18.5301     0.4589       17.7752     19.2850 * #>           1  20.0668     0.4283       19.3623     20.7714 * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Outcome variable: y #>  Qualification variable: partition #>  Control group:  Never Treated #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.1 #>  Analytical standard errors. #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details.  # Group aggregation agg_ddd(out, type = \"group\", alpha = 0.10) #>  Call: #> agg_ddd(ddd_obj = out, type = \"group\", alpha = 0.1) #> ========================= DDD Aggregation ============================ #>  Overall summary of ATT's based on group/cohort aggregation:  #>      ATT    Std. Error     [ 90%  Conf. Int.]   #>  20.7971        0.2922    20.3166     21.2777 * #>  #>  Group Effects: #>  Group Estimate Std. Error [90% Ptwise.  Conf. Band]   #>      2  14.9986     0.3623       14.4026     15.5946 * #>      3  25.4900     0.4594       24.7344     26.2456 * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Outcome variable: y #>  Qualification variable: partition #>  Control group:  Never Treated #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.1 #>  Analytical standard errors. #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details.  # Calendar aggregation agg_ddd(out, type = \"calendar\", alpha = 0.10) #>  Call: #> agg_ddd(ddd_obj = out, type = \"calendar\", alpha = 0.1) #> ========================= DDD Aggregation ============================ #>  Overall summary of ATT's based on calendar time aggregation:  #>      ATT    Std. Error     [ 90%  Conf. Int.]   #>  16.4972        0.2783    16.0395      16.955 * #>  #>  Calendar Effects: #>  Time Estimate Std. Error [90% Ptwise.  Conf. Band]   #>     2   9.9303     0.4422        9.2029     10.6577 * #>     3  23.0642     0.3908       22.4214     23.7069 * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Outcome variable: y #>  Qualification variable: partition #>  Control group:  Never Treated #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.1 #>  Analytical standard errors. #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details."},{"path":"http://marcelortiz.com/triplediff/reference/att_dr.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly robust DDD estimator for ATT, with panel data and 2 periods — att_dr","title":"Doubly robust DDD estimator for ATT, with panel data and 2 periods — att_dr","text":"function implements doubly robust estimator assessing average treatment effect treated (ATT) using triple differences (DDD) approach panel data settings across two time periods. function takes preprocessed data structured specifically analysis.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/att_dr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly robust DDD estimator for ATT, with panel data and 2 periods — att_dr","text":"","code":"att_dr(did_preprocessed)"},{"path":"http://marcelortiz.com/triplediff/reference/att_dr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly robust DDD estimator for ATT, with panel data and 2 periods — att_dr","text":"did_preprocessed list containing preprocessed data specifications DDD estimation. Expected elements include: - preprocessed_data: data table containing data variables needed analysis. - est_method: estimation method used. Default est_method = \"dr\". - xformula: formula covariates included model. form ~ x1 + x2. Default xformla = ~1 (covariates). - boot: Logical. TRUE, function use multiplier bootstrap compute standard errors. Default FALSE. - nboot: number bootstrap samples used. Default NULL. boot = TRUE, default nboot = 999. - subgroup_counts: matrix containing number observations subgroup. - alpha level significance confidence intervals.  Default 0.05. - inffunc: Logical. TRUE, function returns influence function. Default FALSE. - use_parallel: Boolean whether use parallel processing multiplier bootstrap, default use_parallel=FALSE - cores: number cores use parallel processing, default cores=1 - cband: Boolean whether compute simultaneous confidence bands, default cband=FALSE","code":""},{"path":"http://marcelortiz.com/triplediff/reference/att_dr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly robust DDD estimator for ATT, with panel data and 2 periods — att_dr","text":"list estimated ATT, standard error, upper lower confidence intervals, influence function.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_aggregation.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Aggregated Treatment Effect Parameters — compute_aggregation","title":"Compute Aggregated Treatment Effect Parameters — compute_aggregation","text":"heavy lifting computing aggregated group-time average treatment effects","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_aggregation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Aggregated Treatment Effect Parameters — compute_aggregation","text":"","code":"compute_aggregation(   ddd_obj,   type = \"simple\",   cluster = NULL,   balance_e = NULL,   min_e = -Inf,   max_e = Inf,   na.rm = FALSE,   boot = FALSE,   nboot = NULL,   cband = NULL,   alpha = 0.05 )"},{"path":"http://marcelortiz.com/triplediff/reference/compute_aggregation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Aggregated Treatment Effect Parameters — compute_aggregation","text":"ddd_obj ddd object (.e., results ddd() function) type type aggregated treatment effect parameter compute. \"simple\" just computes weighted average group-time average treatment effects weights proportional group size. \"eventstudy\" computes average effects across different lengths exposure treatment (event times). overall effect averages effect treatment across positive lengths exposure. default option; \"group\" computes average treatment effects across different groups/cohorts; overall effect averages effect across different groups using group size weights; \"calendar\" computes average treatment effects across different time periods, weights proportional group size; overall effect averages effect across time period. cluster name variable used clustering. maximum number cluster variables 1. Default NULL. balance_e set (one computes event study), balances sample respect event time.  example, balance_e=2, agg_ddd drop groups exposed treatment least three periods, initial period e=0 well next two periods, e=1 e=2.  ensures composition groups change event time changes. min_e event studies, smallest event time compute dynamic effects .  default, min_e = -Inf effects lengths exposure computed. max_e event studies, largest event time compute dynamic effects .  default, max_e = Inf effects lengths exposure computed. na.rm Logical value remove missing Values analyses. Defaults FALSE. boot Boolean whether compute standard errors using multiplier bootstrap.  standard errors clustered, one must set boot=TRUE. Default value set ddd object.  boot = FALSE, analytical standard errors reported. nboot number bootstrap iterations use.  default value set ddd object, applicable boot=TRUE. cband Boolean whether compute uniform confidence band covers group-time average treatment effects fixed probability 1 - alpha.  order compute uniform confidence bands, boot must also set TRUE.  default value set ddd object alpha level confidence confidence intervals.  default 0.05. Otherwise, use value set ddd object.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_aggregation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Aggregated Treatment Effect Parameters — compute_aggregation","text":"Aggregation object (list) class agg_ddd","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_dml_nuisances.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to compute the DML ATT + score function — compute_dml_nuisances","title":"Function to compute the DML ATT + score function — compute_dml_nuisances","text":"Function compute DML ATT + score function","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_dml_nuisances.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to compute the DML ATT + score function — compute_dml_nuisances","text":"","code":"compute_dml_nuisances(   data,   xformula,   ml_pa,   ml_md,   fold_test,   fold_train,   n_folds )"},{"path":"http://marcelortiz.com/triplediff/reference/compute_dml_nuisances.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to compute the DML ATT + score function — compute_dml_nuisances","text":"data data.table containing data processed xformula formula propensity score model ml_pa mlr3 learner propensity score estimation ml_md mlr3 learner regression adjustment estimation fold_test List test indices global folds fold_train List train indices global folds n_folds number folds cross-fitting","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_dml_nuisances.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to compute the DML ATT + score function — compute_dml_nuisances","text":"list containing ids, estimator k fold, scores","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_se_agg.html","id":null,"dir":"Reference","previous_headings":"","what":"Take influence function and compute standard errors — compute_se_agg","title":"Take influence function and compute standard errors — compute_se_agg","text":"Function take nx1 influence function return standard error","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_se_agg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Take influence function and compute standard errors — compute_se_agg","text":"","code":"compute_se_agg(influence_function, boot = FALSE, boot_std_errors = NA)"},{"path":"http://marcelortiz.com/triplediff/reference/compute_se_agg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Take influence function and compute standard errors — compute_se_agg","text":"influence_function influence function boot boolean indicating whether bootstrapping performed boot_std_errors vector bootstrapped standard errors","code":""},{"path":"http://marcelortiz.com/triplediff/reference/compute_se_agg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Take influence function and compute standard errors — compute_se_agg","text":"scalar standard error","code":""},{"path":"http://marcelortiz.com/triplediff/reference/ddd.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly Robust DDD estimators for the group-time average treatment effects. — ddd","title":"Doubly Robust DDD estimators for the group-time average treatment effects. — ddd","text":"ddd main function computing Doubly Robust DDD estimators ATT, balanced panel data. can used covariates /multiple time periods. core, triplediff employs doubly robust estimator ATT, combination propensity score weighting outcome regression. Furthermore, package supports application machine learning methods estimation nuisance parameters.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/ddd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly Robust DDD estimators for the group-time average treatment effects. — ddd","text":"","code":"ddd(   yname,   tname,   idname,   gname,   pname,   xformla,   data,   control_group = NULL,   base_period = NULL,   est_method = \"dr\",   learners = NULL,   n_folds = NULL,   weightsname = NULL,   boot = FALSE,   nboot = NULL,   cluster = NULL,   cband = FALSE,   alpha = 0.05,   use_parallel = FALSE,   cores = 1,   inffunc = FALSE,   skip_data_checks = FALSE )"},{"path":"http://marcelortiz.com/triplediff/reference/ddd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Doubly Robust DDD estimators for the group-time average treatment effects. — ddd","text":"yname name outcome variable. tname name column containing time periods. idname name column containing unit id. gname name column containing first period particular observation treated. positive number treated units defines group unit belongs . takes value 0 Inf untreated units. pname name column containing partition variable (e.g., subgroup identifier). indicator variable 1 units eligible treatment 0 otherwise. xformla formula covariates included model. form ~ x1 + x2. Default xformla = ~1 (covariates). data data frame data table containing data. control_group Valid multiple periods . control group used estimation. Default control_group = \"notyettreated\" sets control group units yet participated treatment. alternative control_group = \"nevertreated\" sets control group units never participate treatment change across groups time periods. base_period Valid multiple periods. Choose \"varying\" \"universal\" base period. yield post-treatment ATT(g,t) estimates. Varying base period: Computes pseudo-ATT pre-treatment periods comparing outcome changes group comparison group t-1 t, repeatedly changing t. Universal base period: Fixes base period (g-1), reporting average changes t (g-1) group relative comparison group, similar event study regressions. Varying base period reports ATT(g,t) right treatment. Universal base period normalizes estimate treatment 0, adding one extra estimate earlier period. est_method estimation method used. Default \"dr\" (doubly robust). computes propensity score using logistic regression outcome regression using OLS. alternative c(\"reg\", \"ipw\", \"dml\"). last option allows user compute propensity score using machine learning algorithm outcome regression using different machine learning algorithm based mlr3 library. provide examples popular learners user can also provide learner. learners list learners used estimation. list two elements, first element learner propensity score second element learner outcome regression. Default NULL, OLS MLE Logit used estimate nuisances parameters. est_method = \"dml\", user specify learners. n_folds number folds used cross-fitting. Default NULL. est_method = \"dml\", user specify n_folds, least 2. weightsname name column containing weights. Default NULL. part data processing, weights enforced normalized mean 1 across observations. boot Logical. TRUE, function computes standard errors using multiplier bootstrap. Default FALSE. nboot number bootstrap samples used. Default NULL. boot = TRUE, default nboot = 999. cluster name variable used clustering. maximum number cluster variables 1. Default NULL. boot = TRUE, function computes bootstrap standard errors clustering unit level setting cluster variable one idname. cband Logical. TRUE, function computes uniform confidence band covers average treatment effects fixed probability 1-alpha.  order compute uniform confidence bands, boot must also set TRUE.  default FALSE. alpha level significance confidence intervals.  Default 0.05. use_parallel Logical. TRUE, function runs parallel processing. Valid boot = TRUE. Default FALSE. cores number cores used parallel processing. Default cores = 1. inffunc Logical. TRUE, function returns influence function. Default FALSE. skip_data_checks Logical. TRUE, function skips data checks go straight estimation. Default FALSE.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/ddd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Doubly Robust DDD estimators for the group-time average treatment effects. — ddd","text":"ddd object following basic elements: ATT average treatment effect treated. se standard error ATT. uci upper confidence interval ATT. lci lower confidence interval ATT. inf_func estimate influence function.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/ddd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Doubly Robust DDD estimators for the group-time average treatment effects. — ddd","text":"","code":"#---------------------------------------------------------- # Triple Diff with covariates and 2 time periods #---------------------------------------------------------- set.seed(1234) # Set seed for reproducibility # Simulate data for a two-periods DDD setup df <- gen_dgp_2periods(size = 500, dgp_type = 1)$data  head(df) #> Key: <id> #>       id state partition  time        y        cov1       cov2        cov3 #>    <int> <num>     <num> <int>    <num>       <num>      <num>       <num> #> 1:     1     0         0     1 216.3097 -0.97080934  1.3995704  1.48834130 #> 2:     1     0         0     2 430.9374 -0.97080934  1.3995704  1.48834130 #> 3:     2     1         0     1 186.5831  0.02591115 -0.9747527  0.01714001 #> 4:     2     1         0     2 375.9393  0.02591115 -0.9747527  0.01714001 #> 5:     3     0         1     1 425.6606  0.97147321  0.3310760 -1.51021253 #> 6:     3     0         1     2 639.5013  0.97147321  0.3310760 -1.51021253 #>          cov4 cluster #>         <num>   <int> #> 1:  0.3853346      15 #> 2:  0.3853346      15 #> 3: -0.7822000      41 #> 4: -0.7822000      41 #> 5:  0.2334469       5 #> 6:  0.2334469       5  att_22 <- ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",               pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,              data = df, control_group = \"nevertreated\", est_method = \"dr\")  summary(att_22) #>  Call: #> ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",  #>     pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,  #>     data = df, control_group = \"nevertreated\", est_method = \"dr\") #> =========================== DDD Summary ============================== #>  DR-DDD estimation for the ATT:  #>      ATT       Std. Error    Pr(>|t|)  [95% Ptwise. Conf. Band]               #>      0.0439       0.2626       0.8672      -0.4708       0.5586               #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Panel data #>  Outcome variable: y #>  Qualification variable: partition #>  No. of units at each subgroup: #>    treated-and-eligible: 131 #>    treated-but-ineligible: 133 #>    eligible-but-untreated: 116 #>    untreated-and-ineligible: 120 #>  --------------------------- Algorithms ------------------------------ #>  Outcome Regression estimated using: OLS #>  Propensity score estimated using: Maximum Likelihood #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.05 #>  Analytical standard errors. #>  Type of confidence band:  Pointwise Confidence Interval #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details.   #---------------------------------------------------------- # DML Triple Diff with covariates and 2 time periods #---------------------------------------------------------- library(mlr3) library(mlr3learners)  learner_rf <- lrn(\"classif.ranger\", predict_type = \"prob\", num.trees = 100,                min.node.size = 1, importance = 'impurity') #> Warning: Package 'ranger' required but not installed for Learner 'classif.ranger' learner_regr <- lrn(\"regr.xgboost\") #> Warning: Package 'xgboost' required but not installed for Learner 'regr.xgboost'  learners <- list(ml_pa = learner_rf, ml_md = learner_regr)  att_22_dml <- ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",                   pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,                  data = df, control_group = \"nevertreated\",                  est_method = \"dml\", learners = learners, n_folds = 3) #> Warning: Caught packageNotFoundError. Canceling all iterations ... #> Error: The following packages could not be loaded: ranger  summary(att_22_dml) #> Error: object 'att_22_dml' not found  #---------------------------------------------------------- # Triple Diff with multiple time periods #---------------------------------------------------------- data <- gen_dgp_mult_periods(size = 1000, dgp_type = 1)[[\"data\"]]  ddd(yname = \"y\", tname = \"time\", idname = \"id\",      gname = \"state\", pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,      data = data, control_group = \"nevertreated\", base_period = \"varying\",      est_method = \"dr\") #>  Call: #> ddd(yname = \"y\", tname = \"time\", idname = \"id\", gname = \"state\",  #>     pname = \"partition\", xformla = ~cov1 + cov2 + cov3 + cov4,  #>     data = data, control_group = \"nevertreated\", base_period = \"varying\",  #>     est_method = \"dr\") #> =========================== DDD Summary ============================== #>  DR-DDD estimation for the ATT(g,t):  #> Group Time  ATT(g,t)  Std. Error [95% Pointwise  Conf. Band]   #>   2    2      10.1524     0.3198       9.5256       10.7792  * #>   2    3      20.2460     0.3203      19.6182       20.8738  * #>   3    2       0.0815     0.2652      -0.4384        0.6013    #>   3    3      25.0675     0.2799      24.5189       25.6161  * #>  #>  Note: * indicates that the confidence interval does not contain zero. #>  --------------------------- Data Info   ----------------------------- #>  Panel data #>  Outcome variable: y #>  Qualification variable: partition #>  Control group: Never Treated #>  No. of units per treatment group: #>   Units enabling treatment at period 3: 477 #>   Units enabling treatment at period 2: 309 #>   Units never enabling treatment: 214 #>  --------------------------- Algorithms ------------------------------ #>  Outcome Regression estimated using: OLS #>  Propensity score estimated using: Maximum Likelihood #>  --------------------------- Std. Errors  ---------------------------- #>  Level of significance:  0.05 #>  Analytical standard errors. #>  Type of confidence band:  Pointwise Confidence Interval #>  ===================================================================== #>  See Ortiz-Villavicencio and Sant'Anna (2025) for details."},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_2periods.html","id":null,"dir":"Reference","previous_headings":"","what":"Function that generates panel data with single treatment date assignment and two time periods. — gen_dgp_2periods","title":"Function that generates panel data with single treatment date assignment and two time periods. — gen_dgp_2periods","text":"Generate panel data single treatment date two periods","code":""},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_2periods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function that generates panel data with single treatment date assignment and two time periods. — gen_dgp_2periods","text":"","code":"gen_dgp_2periods(size, dgp_type)"},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_2periods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function that generates panel data with single treatment date assignment and two time periods. — gen_dgp_2periods","text":"size Integer. Number units. dgp_type Integer {1,2,3,4}. 1 = nuisance functions correct; 2 = outcome model correct; 3 = propensity score correct; 4 = nuisance functions incorrect.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_2periods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function that generates panel data with single treatment date assignment and two time periods. — gen_dgp_2periods","text":"list following elements: data data.table long format columns: id: unit identifier state: state variable time: time variable partition: partition assignment x1, x2, x3, x4: covariates y: outcome variable cluster: cluster ID (within-cluster correlation) att True average treatment effect treated (ATT), set 0. att.unf “Oracle” ATT computed unfeasible specification. eff Theoretical efficiency bound estimator.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_mult_periods.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate panel data with staggered treatment adoption (three periods) — gen_dgp_mult_periods","title":"Generate panel data with staggered treatment adoption (three periods) — gen_dgp_mult_periods","text":"Generate panel data units adopt treatment different times across three periods.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_mult_periods.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate panel data with staggered treatment adoption (three periods) — gen_dgp_mult_periods","text":"","code":"gen_dgp_mult_periods(size, dgp_type = 1)"},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_mult_periods.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate panel data with staggered treatment adoption (three periods) — gen_dgp_mult_periods","text":"size Integer. Number units simulate. dgp_type Integer {1,2,3,4}. 1 = nuisance functions correct; 2 = outcome model correct; 3 = propensity-score model correct; 4 = nuisance functions misspecified.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/gen_dgp_mult_periods.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate panel data with staggered treatment adoption (three periods) — gen_dgp_mult_periods","text":"named list components: data data.table long format columns: id: unit identifier cohort: first period treatment assigned partition: partition indicator x1, x2, x3, x4: covariates cluster: cluster identifier (within-cluster correlation) time: time period index y: observed outcome data_wide data.table wide format (one row per id) columns: id, cohort, partition, x1, x2, x3, x4, cluster y_t0, y_t1, y_t2: outcomes periods 0, 1, 2 ES_0_unf Unfeasible (oracle) event-study parameter time 0. prob_g2_p1 Proportion units cohort == 2 eligibility period 1. prob_g3_p1 Proportion units cohort == 3 eligibility period 1.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/generate_test_panel.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to generate a fake dataset for testing purposes only. — generate_test_panel","title":"Function to generate a fake dataset for testing purposes only. — generate_test_panel","text":"Function generate fake dataset test internal procedures.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/generate_test_panel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to generate a fake dataset for testing purposes only. — generate_test_panel","text":"","code":"generate_test_panel(   seed = 123,   num_ids = 100,   time = 2,   initial.year = 2019,   treatment.year = 2020 )"},{"path":"http://marcelortiz.com/triplediff/reference/generate_test_panel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to generate a fake dataset for testing purposes only. — generate_test_panel","text":"seed Seed reproducibility num_ids Number IDs time Number time periods initial.year Initial year treatment.year Treatment year","code":""},{"path":"http://marcelortiz.com/triplediff/reference/generate_test_panel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to generate a fake dataset for testing purposes only. — generate_test_panel","text":"data.table following columns: id: ID state: State variable year: Time variable partition: Partition variable x1: Covariate 1 x2: Covariate 2 treat: Treatment variable outcome: Outcome variable","code":""},{"path":"http://marcelortiz.com/triplediff/reference/get_agg_inf_func.html","id":null,"dir":"Reference","previous_headings":"","what":"Get an influence function for particular aggregate parameters — get_agg_inf_func","title":"Get an influence function for particular aggregate parameters — get_agg_inf_func","text":"Get influence function particular aggregate parameters generic internal function combining influence functions across ATT(g,t)'s return influence function various aggregated treatment effect parameters.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/get_agg_inf_func.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get an influence function for particular aggregate parameters — get_agg_inf_func","text":"","code":"get_agg_inf_func(att, inf_func, whichones, weights_agg, wif = NULL)"},{"path":"http://marcelortiz.com/triplediff/reference/get_agg_inf_func.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get an influence function for particular aggregate parameters — get_agg_inf_func","text":"att vector group-time average treatment effects inf_func influence function group-time average treatment effects (matrix) whichones elements att used compute aggregated treatment effect parameter weights_agg weights apply element att(whichones); dimension att(whichones) wif extra influence function term coming estimating weights; n x k matrix k dimension whichones","code":""},{"path":"http://marcelortiz.com/triplediff/reference/get_agg_inf_func.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get an influence function for particular aggregate parameters — get_agg_inf_func","text":"nx1 influence function","code":""},{"path":"http://marcelortiz.com/triplediff/reference/get_local_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to get local sample indices for ","title":"Function to get local sample indices for ","text":"Function get local sample indices \"local\" DiDs comparisons.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/get_local_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to get local sample indices for ","text":"","code":"get_local_folds(units_selected, n_folds, global_fold_test, global_fold_train)"},{"path":"http://marcelortiz.com/triplediff/reference/get_local_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to get local sample indices for ","text":"units_selected Vector units selected local sample n_folds Number folds global_fold_test List test indices global folds global_fold_train List train indices global folds","code":""},{"path":"http://marcelortiz.com/triplediff/reference/get_local_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to get local sample indices for ","text":"list containing train test indices fold local level.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/make_stratified_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratified K-fold splits for cross-fitting Quickly builds train and test index lists that preserve the class proportions of a categorical variable in every fold — make_stratified_folds","title":"Stratified K-fold splits for cross-fitting Quickly builds train and test index lists that preserve the class proportions of a categorical variable in every fold — make_stratified_folds","text":"Stratified K-fold splits cross-fitting Quickly builds train test index lists preserve class proportions categorical variable every fold","code":""},{"path":"http://marcelortiz.com/triplediff/reference/make_stratified_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratified K-fold splits for cross-fitting Quickly builds train and test index lists that preserve the class proportions of a categorical variable in every fold — make_stratified_folds","text":"","code":"make_stratified_folds(data, strat_col, n_folds = 2, seed = NULL)"},{"path":"http://marcelortiz.com/triplediff/reference/make_stratified_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratified K-fold splits for cross-fitting Quickly builds train and test index lists that preserve the class proportions of a categorical variable in every fold — make_stratified_folds","text":"data data.frame / data.table least column named strat_col. comes preprocessing steps. strat_col Character scalar. Column used stratification (e.g. \"subgroup\"). n_folds Integer ≥ 2. Number folds. Default 2. seed Optional integer. supplied, function calls set.seed() reproducible splits.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/make_stratified_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stratified K-fold splits for cross-fitting Quickly builds train and test index lists that preserve the class proportions of a categorical variable in every fold — make_stratified_folds","text":"list two components — test_ids train_ids — length-K list integer vectors.  exact structure expected DoubleML:","code":"splits$train_ids[[j]]  # rows used to fit learners   (fold j)         splits$test_ids [[j]]  # rows used to compute scores (fold j)"},{"path":"http://marcelortiz.com/triplediff/reference/mboot.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiplier Bootstrap — mboot","title":"Multiplier Bootstrap — mboot","text":"function take influence function use multiplier bootstrap compute standard errors critical values uniform confidence bands.","code":""},{"path":"http://marcelortiz.com/triplediff/reference/mboot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiplier Bootstrap — mboot","text":"","code":"mboot(inf_func, did_preprocessed, use_parallel = FALSE, cores = 1)"},{"path":"http://marcelortiz.com/triplediff/reference/mboot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiplier Bootstrap — mboot","text":"inf_func influence function did_preprocessed dp object obtained preprocess use_parallel Boolean whether use parallel processing multiplier bootstrap, default use_parallel=FALSE cores number cores use parallel processing, default cores=1","code":""},{"path":"http://marcelortiz.com/triplediff/reference/mboot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiplier Bootstrap — mboot","text":"list following elements bres results bootstrap iteration. V variance matrix. se standard errors. crit_val critical value computing uniform confidence bands.","code":""},{"path":"http://marcelortiz.com/triplediff/news/index.html","id":"triplediff-010","dir":"Changelog","previous_headings":"","what":"triplediff 0.1.0","title":"triplediff 0.1.0","text":"Initial release triplediff alpha stage, functions computing group-time average treatment effects DDD combining smaller number parameters available.","code":""}]
